# 1. СТРУКТУРЫ ДАННЫХ

Конспект для подготовки к экзамену по курсу «Информатика (организация и поиск данных)».

---

## 1.1. Классификация структур данных

**По способу размещения в памяти:**
- **Последовательные (континуальные)** — элементы хранятся в смежных ячейках подряд. Адрес i-го элемента: `base + i * sizeof(T)` — линейная адресация. Прямой доступ за O(1): индекс преобразуется в адрес одной арифметической операцией. Недостаток: вставка или удаление в середине требует сдвига всех последующих элементов — O(n). Хорошая кеш-локальность: последовательный обход обращается к смежным адресам.
- **Связанные** — каждый элемент (узел) содержит данные и указатели на соседей. Элементы могут быть разбросаны по памяти. Вставка и удаление при наличии указателя на узел — O(1), так как достаточно обновить связи. Нет прямого доступа по индексу: для i-го элемента нужен обход O(i).
- **Комбинированные** — сочетают оба подхода. Хеш-таблица: массив бакетов (континуально) и цепочки узлов в бакетах при коллизиях (связанные).

**По типу доступа:**
- **Прямой (Random Access)** — доступ к элементу по индексу за O(1). Примеры: массив, динамический массив.
- **Последовательный** — обход только в порядке следования, вперёд или вперёд-назад. Примеры: список, поток.
- **Ассоциативный** — доступ по ключу. Хеш — O(1) в среднем, дерево — O(log n).

**По динамичности:** статические (размер задан при создании) / динамические (размер может расти и уменьшаться).

**По мутабельности:** изменяемые (операции модифицируют структуру in-place) / неизменяемые (каждая операция возвращает новую структуру, исходная не меняется).

---

## 1.2. Массивы, динамические массивы. Основные операции, асимптотика

**Статический массив** — непрерывный блок памяти фиксированного размера. Синтаксис `arr[i]` эквивалентен `*(arr + i)`: адресная арифметика. Компилятор учитывает sizeof(T), поэтому сдвиг на i элементов, а не байт. Прямой доступ O(1).

**Динамический массив** хранит: указатель на буфер, size (текущее число элементов), capacity (размер выделенной памяти). При push_back: если size < capacity, просто записываем в конец. Если size >= capacity, выделяем новый буфер (обычно в 2 раза больше), копируем все элементы, освобождаем старый. Стоимость одного push_back в худшем случае O(n), но амортизированно O(1).

**Амортизированный анализ (метод банкира):** при каждой вставке «платим» две монеты — одну на саму запись, вторую «откладываем». При удвоении буфера накопленные монеты покрывают копирование: каждый из n элементов при последнем копировании тратит одну монету. Итого n вставок — O(n) работы, т.е. O(1) на операцию в среднем.

**Вставка в начало или середину** — сдвиг всех последующих элементов вправо, O(n). **Удаление** — сдвиг влево, O(n).

| Операция | Оценка |
|----------|--------|
| Доступ по индексу | O(1) |
| push_back | O(1) амортиз. |
| Вставка в начало/середину | O(n) |
| Удаление | O(n) |

---

## 1.3. Связанные списки и их вариации

**Односвязный список:** узел содержит данные и указатель next на следующий. Храним head (и tail для O(1) push_back). push_front — новый узел в начало, O(1). push_back — в конец при наличии tail, O(1). insert_after(узел) — вставка после заданного узла, O(1). remove_after(узел) — удаление следующего, O(1). Удаление заданного узла при отсутствии указателя на предыдущий требует обхода O(n). Поиск по значению — O(n).

**Двусвязный список:** узел `{data, prev, next}`. При вставке и удалении обновляем связи соседей с обеих сторон — O(1) при указателе на узел. Удаление текущего узла без поиска предыдущего — O(1). Дополнительная память на один указатель на узел.

**Линейный** — последний узел имеет next = nullptr. **Кольцевой** — последний указывает на первый, tail->next = head. В двусвязном кольце также head->prev = tail. Обход — по счётчику или до возврата к началу. Удобно для циклических очередей, round-robin.

---

## 1.4. Очередь. Способы реализации и оценка асимптотики

**Очередь FIFO** — First In, First Out. Операции: enqueue (добавить в конец), dequeue (извлечь из начала).

**Кольцевой буфер:** массив фиксированного размера, индексы head и tail. При enqueue пишем в tail, tail = (tail+1) % capacity. При dequeue читаем из head, head = (head+1) % capacity. Обе операции O(1). Переполнение — когда (tail+1)%capacity == head. При необходимости расширения — перераспределение с копированием O(n).

**На связном списке:** храним указатели на голову и хвост. enqueue — вставка в конец (после tail), dequeue — удаление из начала. O(1) для обеих операций. Размер не ограничен (если не ограничена память).

---

## 1.5. Стек. Способы реализации и оценка асимптотики

**Стек LIFO** — Last In, First Out. Операции: push (положить наверх), pop (снять сверху), top (посмотреть верхний без извлечения).

**На динамическом массиве:** вершина стека — конец массива. push = push_back, pop = pop_back, top = доступ к последнему элементу. O(1) амортизированно для push, O(1) для pop и top.

**На односвязном списке:** вершина стека — голова списка. push — вставка в начало, pop — удаление из начала. O(1) на все операции. Не требует предварительного выделения памяти под размер.

---

## 1.6. Двоичная куча. Основные операции. Способы реализации и оценка асимптотики

**Инвариант кучи:** для каждого узла родитель не меньше (max-heap) или не больше (min-heap) обоих детей. Полное бинарное дерево — все уровни заполнены слева направо, кроме, возможно, последнего.

**Хранение в массиве:** обход по уровням (слева направо). Для индекса i: родитель (i-1)/2, левый ребёнок 2i+1, правый 2i+2. Нет указателей, хорошая кеш-локальность.

**siftUp (просеивание вверх):** при вставке ставим новый элемент в конец массива. Пока он нарушает инвариант с родителем — меняем местами с родителем. O(log n) — не более высоты дерева.

**siftDown (просеивание вниз):** при извлечении максимума (min-heap — минимума) ставим последний элемент в корень. Пока он нарушает инвариант с детьми — меняем с большим (или меньшим для min-heap) ребёнком. O(log n).

**Heapify (построение кучи из массива):** вызываем siftDown для всех внутренних узлов от (n/2)-1 до 0 (снизу вверх). Анализ: сумма «высот» узлов даёт O(n), а не O(n log n), т.к. большинство узлов близко к листьям.

**Иллюстрации (max-heap):**

Дерево и массив (обход по уровням):
```
        9
       / \
      7   5
     / \ / \
    4  3 2  1

индекс:  0  1  2  3  4  5  6
массив: [9, 7, 5, 4, 3, 2, 1]
```

**push(6) — вставка и siftUp:** ставим 6 в конец, поднимаем вверх, пока родитель меньше.

До:
```
        9
       / \
      7   5
     / \ / \
    4  3 2  1
```

После добавления 6 в конец:
```
        9
       / \
      7   5
     / \ / \ \
    4  3 2  1  6
```

После siftUp (6 поднялась, обмен с 5; 5 ушла вниз, левый потомок 4):
```
        9
       / \
      7   6
     / \ / \
    4  3 2  1
   /
  5
```
Массив: [9,7,5,4,3,2,1] → [9,7,5,4,3,2,1,6] → [9,7,6,4,3,2,1,5].

**pop() — извлечение максимума и siftDown:** забираем корень (9), на корень ставим последний (1), просеиваем вниз, меняя с большим ребёнком.

Было:
```
        9
       / \
      7   6
     / \ / \
    4  3 2  1
```

Убрали 9, на корень поставили последний (1):
```
        1
       / \
      7   6
     / \ /
    4  3 2
```

После siftDown (1 → обмен с 7, затем с 4):
```
        7
       / \
      4   6
     / \ /
    1  3 2
```
Шаги: 1 < 7 и 1 < 6 → меняем с большим (7); 1 < 4 и 1 < 3 → меняем с 4; 1 в листе. Массив: [9,7,6,4,3,2,1] → [1,7,6,4,3,2] → [7,4,6,1,3,2].

| Операция | Оценка |
|----------|--------|
| push | O(log n) |
| pop | O(log n) |
| peek | O(1) |
| heapify | O(n) |

---

## 1.7. Поток данных (stream). Основные операции, способы реализации, сравнительная характеристика и асимптотика

**Что такое поток.** Поток (stream) — это абстракция **последовательного доступа** к данным: мы не прыгаем к произвольному элементу по индексу, а «идём» по данным шаг за шагом, от начала к концу. Один и тот же интерфейс (hasNext, read) можно использовать для разных источников: массив в памяти, файл на диске, данные из сети. Код, который обрабатывает поток, не знает, откуда приходят байты — это упрощает переиспользование (например, один парсер для файла и для сетевого сокета).

**Последовательный vs прямой доступ.** Прямой (random access): обращение к элементу по индексу за O(1) — массив, `arr[i]`. Последовательный: следующий элемент получаем только после предыдущего — как лента: сдвинулись вперёд, прочитали следующий байт. Поток — это как раз модель «ленты».

**Основные операции:**
- **hasNext()** (или **eof()** — end of stream) — есть ли ещё данные для чтения. Перед каждым read обычно проверяют hasNext, чтобы не читать за концом.
- **read()** — вернуть **следующий** элемент и сдвинуть «курсор» вперёд. Элемент может быть байт, символ или запись фиксированного размера — зависит от типа потока.
- Для **входного потока** только чтение. Для **выходного** — **write(x)** — записать следующий элемент.
- **Двунаправленный** поток (файл, открытый на чтение и запись) может поддерживать **seek(pos)** — перейти к позиции pos для следующего read/write. Тогда доступ не строго последовательный.

**Реализация потока из массива.** Данные уже в памяти: массив `data[]` и его `size`. Храним текущую позицию `pos` (индекс следующего элемента для чтения). **hasNext** — `pos < size`. **read()** — вернуть `data[pos]` и увеличить `pos` на 1 (т.е. `data[pos++]`). Обе операции O(1). Вся память под массив уже выделена, обращений к ОС нет. Если нужен произвольный доступ — можно добавить **seek(pos)**: просто присвоить внутренней позиции значение pos; тогда поток ведёт себя как «вид» на массив с текущей позицией.

**Реализация потока из файла.** Данные на диске; каждое обращение к файлу — системный вызов (read/write), он дорогой. **Буферизация:** вместо «один байт — один вызов» читаем **блок** (например 4 KB) в буфер в памяти. **read()** отдаёт байты из буфера по одному (или небольшими порциями); когда буфер опустел — следующий вызов read в ОС, заполняем буфер снова. Так один системный вызов даёт много байт — число обращений к диску и ядру падает. **read()** из буфера — O(1); редкие «подкачки» с диска — O(размер_блока). **seek(pos)** на файле может требовать позиционирования на диске (O(1) в кэше ОС, но при реальном сдвиге головки — дороже); для чисто последовательного чтения seek не нужен.

**Сравнение.** Массив: минимум накладных расходов, O(1) на read и seek, всё в RAM. Файл: ограничен скоростью диска и системными вызовами; буфер сглаживает это при последовательном чтении. Для последовательной обработки (парсинг, копирование) оба дают «потоковый» интерфейс; выбор зависит от того, откуда данные изначально (память vs диск/сеть) и нужен ли произвольный доступ.

---

## 1.8. Очередь с приоритетами. Способы реализации и оценка асимптотики

**Что такое очередь с приоритетами.** Абстрактный тип данных: элементы имеют приоритет (число или ключ). Извлекаем не «первый пришедший» (как в FIFO), а элемент с **наивысшим** (или **наименьшим**) приоритетом. Два варианта: **extractMin** — минимум приоритета первым (задачи с «меньше = срочнее»); **extractMax** — максимум первым. Остальной интерфейс тот же: вставка и просмотр экстремума без извлечения.

**Операции АТД:**
- **insert(x)** — добавить элемент x с его приоритетом.
- **extractMin()** (или **extractMax()**) — вернуть и удалить элемент с минимальным (максимальным) приоритетом. Обычно не определено для пустой очереди.
- **peek()** (или **findMin** / **findMax**) — вернуть экстремум **без** удаления. O(1), если храним его в известном месте.

**Примеры использования:** планировщик задач (срочность = приоритет), алгоритм Дейкстры (извлечение вершины с минимальным расстоянием), слияние k отсортированных последовательностей (минимум среди текущих голов — приоритет).

**Реализация на бинарной куче (min-heap для extractMin).** Куча хранит элементы по приоритету: в корне — минимум. **insert:** добавляем в конец массива (новый лист), затем **siftUp** — поднимаем, пока родитель больше. O(log n). **extractMin:** забираем корень (это минимум), на место корня ставим последний элемент массива, затем **siftDown** — опускаем, пока кто-то из детей меньше. O(log n). **peek:** корень кучи — O(1). И вставка, и извлечение за O(log n), без перебора всех элементов — удобно, когда и вставок, и извлечений много (типичный случай в алгоритмах).

**Реализация на отсортированном связном списке.** Список упорядочен по приоритету (например, от меньшего к большему). **extractMin** — удаление головы списка, O(1). **insert** — поиск места вставки (обход до первого элемента с большим приоритетом), вставка узла O(1), но поиск O(n). **peek** — голова списка, O(1). Получается: извлечение дёшево, вставка дорогая. Выгодно, если извлечений мало, а вставок много (или наоборот — тогда держим порядок «от большего к меньшему» и extractMax = голова).

**Сравнение.** Куча: insert O(log n), extractMin O(log n), peek O(1) — сбалансировано; дополнительная память — массив под кучу, без указателей на узлы. Отсортированный список: extractMin O(1), insert O(n), peek O(1) — выбор имеет смысл, когда одна из операций резко преобладает. В общем случае для очереди с приоритетами обычно используют кучу.

---

## 1.9. Бинарное дерево поиска. Основные операции. Балансировка. Оценка асимптотики

**Инвариант BST:** для каждого узла все ключи в левом поддереве меньше ключа узла, в правом — больше (или наоборот при другом порядке). Inorder-обход даёт отсортированную последовательность.

**Поиск:** спуск от корня — влево, если key меньше, вправо, если больше. O(h), где h — высота. В сбалансированном дереве h = O(log n), в вырожденном (цепочка) h = O(n).

**Вставка:** спуск до «провала» (nullptr), создание нового узла на этом месте. O(h).

**Удаление — три случая:** (1) нет детей — просто удалить узел; (2) один ребёнок — поднять ребёнка на место удаляемого; (3) два ребёнка — заменить ключ удаляемого на минимум правого поддерева, рекурсивно удалить тот минимум (у него нет левого сына, сводится к случаю 1 или 2). Минимум правого поддерева — единственный кандидат, сохраняющий инвариант при переносе в корень.

**Балансировка:** AVL — разница высот поддеревьев не более 1, повороты при нарушении. Красно-чёрное дерево — инварианты по цветам, перекрашивание и повороты. Гарантируют h = O(log n).

**Иллюстрации:**

Инвариант BST: слева от узла — меньшие, справа — большие. Inorder (левый → узел → правый) даёт порядок по возрастанию.
```
          5
         / \
        3   8
       / \   \
      1   4   9

Inorder: 1, 3, 4, 5, 8, 9
```

**Поиск (например, 4):** спуск от корня — 4 < 5 → влево; 4 > 3 → вправо; нашли 4.
```
          5
         / \     ищем 4: 5 → 3 → 4
        3   8
       / \   \
      1   4   9
```

**Вставка (6):** спуск до «провала» — 6 > 5 → вправо; 6 < 8 → влево; у 8 нет левого сына — вешаем 6.
```
  До:        5      После вставки 6:    5
           / \                        / \
          3   8                      3   8
         / \   \                    / \ / \
        1   4   9                  1  4 6  9
```

**Удаление — три случая:**

(1) Узел без детей — просто убрать ссылку.
```
  Удаляем 4:    5            Стало:    5
               / \                    / \
              3   8                  3   8
             / \   \                /   \
            1   4   9              1    9
```

(2) Один ребёнок — поднять ребёнка на место удаляемого.
```
  Удаляем 8:    5            Стало:    5
               / \                    / \
              3   8                  3   9
             / \   \                / \
            1   4   9              1   4
```

(3) Два ребёнка — заменить ключ удаляемого на минимум правого поддерева, удалить тот минимум (у него нет левого сына).
```
  Удаляем 5:    5            Минимум правого (поддерево 8): 6.
               / \           5 заменяем на 6, удаляем старую 6:
              3   8
             / \ / \
            1  4 6  9

  Стало:        6
             /   \
            3     8
           / \     \
          1   4     9
```

**Вырожденное дерево (цепочка)** — высота O(n), поиск/вставка O(n). **Сбалансированное** — высота O(log n), операции O(log n).
```
Вырожденное:    1     Сбалансированное:    5
                 \                        / \
                  2                      3   8
                   \                    / \   \
                    3                  1   4   9
                     \
                      4
```

---

## 1.10. Понятие итератора, основные операции

**Итератор** — объект, абстрагирующий позицию в контейнере. Позволяет унифицировать обход разных структур.

**Основные операции:** разыменование `*it` (доступ к элементу), инкремент `++it` (переход к следующему), сравнение с end `it != end` (проверка конца). Для Bidirectional — `--it`. Для Random Access — `it + k`, `it - k`, `it[k]`.

**Категории итераторов (по нарастанию возможностей):** Input (один проход, только чтение); Forward (многократный проход); Bidirectional (+ движение назад); Random Access (+ произвольный доступ за O(1)). Алгоритмы требуют минимально необходимой категории — например, sort требует Random Access, reverse — Bidirectional.

---

## 1.11. Тип Option&lt;&gt;

Представляет «возможно отсутствующее» значение. Два варианта: Some(value) или None. Альтернатива nullptr — делает отсутствие явным в типе, компилятор требует обработку обоих случаев.

**Реализация:** union для хранения значения + флаг has_value (или отдельный «пустой» битовый паттерн). Для не-POD типов при копировании нужен placement new. C++17: `std::optional<T>`.

---

## 1.12. Тип Either&lt;&gt;

«Либо одно, либо другое» — объединение двух типов в один. Left(l) или Right(r). В отличие от Option, хранит информацию о причине «отсутствия».

**Применение Result&lt;T, Error&gt;:** Left — ошибка (с деталями), Right — успешный результат. Возврат ошибок без исключений, явная обработка в коде.

---

## 1.13. N-арные деревья. B- и B+-деревья. Основные операции, оценка асимптотики

**B-дерево порядка t:** каждый узел содержит от t до 2t ключей (кроме корня) и от t+1 до 2t+1 указателей на детей. Все листья на одной глубине — дерево сбалансировано. Высота O(log_t n). При переполнении узла — split: средний ключ поднимается в родителя, узел разбивается на два. Оптимизировано для диска — мало обращений к узлам, большой размер узла (страница).

**B+-дерево:** данные хранятся только в листьях; внутренние узлы содержат копии ключей для маршрутизации поиска. Листья связаны в двусвязный список — быстрый последовательный обход и диапазонные запросы. Поиск O(log n), вставка O(log n).

---

## 1.14. Хеш-таблицы. Хеш-функции. Разрешение коллизий в хеш-таблицах

**Принцип:** ключ преобразуется хеш-функцией h в индекс массива. Идеально — O(1) доступ. Коллизия — разные ключи дают один индекс.

**Хеш-функция** должна быть детерминированной, быстрой и равномерно распределять ключи. djb2: h = h*33 + c. FNV-1a: xor и умножение на простое. Для строк — итерация по символам.

**Load factor** α = число элементов / число бакетов. При α > 0.7–1.0 растёт число коллизий. Rehash — создание новой таблицы с большим числом бакетов (×2), пересчёт хешей для всех элементов, O(n).

**Chaining:** каждый бакет — список пар (ключ, значение). При коллизии добавляем в список. Поиск O(1 + α) в среднем. Просто, устойчиво к переполнению.

**Open addressing:** все элементы в одном массиве. При коллизии — пробирование: линейное (i+1) mod n — просто, но кластеризация; квадратичное i + k²; двойное хеширование i + h2(key). При удалении — tombstone (помечаем ячейку удалённой), чтобы не обрывать цепочку при поиске.

---

## 1.15. Общие алгоритмы на перечислимых контейнерах: map, reduce, where

**map(f, xs)** — применить функцию f к каждому элементу, вернуть новую последовательность тех же размеров. O(n). Пример: map(square, [1,2,3]) → [1,4,9].

**reduce(init, f, xs)** — свёртка: начальное значение init, на каждом шаге init = f(init, x). Итог — одно значение. O(n). Пример: reduce(0, add, xs) — сумма; reduce(1, mul, xs) — произведение.

**where(pred, xs)** — фильтр: оставить только элементы, для которых pred(x) истинно. O(n). Пример: where(is_even, xs) — только чётные.

---

## 1.16. Понятие монады (как идиомы и структуры данных). Пример

**Монада** — абстракция для последовательных вычислений с контекстом. Операции: return (упаковать значение в монаду) и bind (применить функцию к значению внутри монады, функция возвращает монаду). Законы: ассоциативность bind, left/right identity.

**Option как монада:** return(x) = Some(x). bind(m, f) — если m = Some(x), то f(x); иначе None. Позволяет комбинировать вычисления, которые могут «не дать результата», без явных if на каждом шаге. Пример: `find(id).bind(getAge).bind(validate)` — если find вернул None, вся цепочка даёт None; иначе результат проходит через getAge и validate.
